# Space Station Object Detection with YOLOv8

![Space Station Detection](https://img.shields.io/badge/Space%20Station-Object%20Detection-blue)
![YOLOv8](https://img.shields.io/badge/Model-YOLOv8-brightgreen)
![Status](https://img.shields.io/badge/Status-In%20Development-yellow)

This project implements an advanced object detection system for space station environments using YOLOv8. The model is specifically trained to identify critical equipment aboard space stations: `FireExtinguisher`, `ToolBox`, and `OxygenTank` - all essential for astronaut safety and operational efficiency.


[Google Collab URL](https://colab.research.google.com/drive/1X74FUMYBhxSpbf7qEGIdXQlU-Q5alBzA?usp=sharing) 
## Project Overview

Space station environments present unique challenges for object detection systems:
- Variable lighting conditions (from bright to extremely dim)
- Complex geometries with frequent occlusions
- Limited computational resources for deployment
- Critical importance of accurate equipment tracking

Our solution leverages synthetic data generated by Duality AI's Falcon simulator to train a YOLOv8 model that can reliably detect these objects under various conditions. This approach demonstrates how synthetic data can effectively train models for environments where real-world data collection is impractical or impossible.

## Project Structure

```
HackByte_Dataset/
├── data/                  # Contains train, val, test folders with images and labels
│   ├── train/             # Training images and labels
│   ├── val/               # Validation images and labels
│   └── test/              # Test images and labels
├── reports/               # Generated reports and visualizations
│   ├── eval_exp_space/    # Evaluation results
│   └── visualizations/    # Visualizations of model performance
├── runs/                  # Training runs and model weights
│   └── exp_space/         # Experiment outputs
├── classes.txt            # List of object categories
├── train.py               # Training script for YOLOv8
├── predict.py             # Inference and evaluation
├── visualize.py           # For result visualizations 
├── yolo_params.yaml       # YOLOv8 training parameters
├── streamlit_app.py       # Interactive web app for inference
└── README.md              # This file
```

## Setup Instructions

### Requirements

- Python 3.8+
- PyTorch 1.8+
- Ultralytics YOLOv8
- OpenCV
- Matplotlib
- Pandas
- PyYAML
- Streamlit (for the web app)
- CUDA-capable GPU (recommended for training)

### Installation

1. Clone this repository:
   ```bash
   git clone https://github.com/yourusername/space-station-detection.git
   cd space-station-detection
   ```

2. Install the required packages:
   ```bash
   pip install -r requirements.txt
   ```
   
   Alternatively, install packages individually:
   ```bash
   pip install ultralytics opencv-python matplotlib pyyaml streamlit pandas seaborn
   ```

3. Download pre-trained weights (if not included in the repository):
   ```bash
   curl -L https://github.com/ultralytics/assets/releases/download/v0.0.0/yolov8s.pt -o yolov8s.pt
   ```

## Dataset

The project uses a synthetic dataset generated by Duality AI's Falcon simulator, which creates realistic space station environments with:

- Various lighting conditions (well-lit, dim, shadowed)
- Multiple camera angles and distances
- Realistic occlusions and object placements
- Accurate object models and textures

The dataset contains three object classes critical for space station operations:
1. **FireExtinguisher**: Essential safety equipment
2. **ToolBox**: Contains maintenance tools and equipment
3. **OxygenTank**: Critical life support equipment

## Usage

### Training the Model

To train the model with parameters from `yolo_params.yaml`:

```bash
python train.py
```

The training script will:
- Load hyperparameters from the YAML configuration
- Train using the specified dataset and augmentation strategies
- Save logs, checkpoints, and the best model to the `runs/exp_space` directory
- Print summary metrics after training

Custom training parameters can be specified:

```bash
python train.py --epochs 30 --batch 8 --device 0
```

### Evaluating the Model

To evaluate the model on the test set:

```bash
python predict.py
```

This will:
1. Load the best model weights from training
2. Run predictions on images in the test set
3. Calculate evaluation metrics (mAP@0.5, precision, recall)
4. Generate a confusion matrix and other analysis artifacts
5. Save results to the `reports/eval_exp_space` directory

### Generating Visualizations

To create comprehensive visualizations of model performance:

```bash
python visualize.py
```

This generates:
- Confusion matrix
- Precision-Recall curves by class
- mAP curves over training epochs
- Sample predictions with before/after comparisons
- Dataset distribution analysis

Visualizations are saved to the `reports/visualizations` directory.

### Interactive Web App

Launch the Streamlit web application for real-time inference:

```bash
streamlit run streamlit_app.py
```

The web app provides:
- Image upload functionality
- Real-time object detection
- Visualization of detection results
- Confidence threshold adjustment
- Detection metrics display

## Technical Approach

### Model Architecture

The project utilizes YOLOv8, a state-of-the-art object detection architecture that offers:
- Single-stage detection for real-time performance
- Feature pyramid networks for multi-scale detection
- Mosaic augmentation for improved small object detection
- Anchor-free detection with more flexible predictions

### Training Strategy

Our training approach includes:
- Transfer learning from pretrained weights
- Custom data augmentation pipeline
- Optimized learning rate scheduling
- Balanced loss function weighting
- Early stopping to prevent overfitting

### Optimization Techniques

To achieve the best performance, we employ:
- Advanced augmentation strategies (mosaic, HSV adjustments)
- Hyperparameter tuning via configuration files
- Class-specific confidence thresholds
- Non-Maximum Suppression optimization


## Challenges and Solutions

### Current Challenges

- **Occlusion Handling**: Objects partially hidden behind station equipment
  
- **Lighting Variation**: Extreme lighting differences between modules

- **Object Similarity**: Similar visual appearance between classes

- **Small Object Detection**: Equipment appearing small in wide-angle views

### Implemented Solutions

- Advanced data augmentation techniques
- Transfer learning from pretrained models
- Optimized confidence thresholds
- Detailed failure case analysis

## Development Roadmap

- [x] Initial model training and baseline establishment
- [x] Hyperparameter optimization via YAML configuration
- [x] Evaluation pipeline implementation
- [x] Visualization tools development
- [x] Interactive web app creation
- [ ] Failure case analysis and model refinement
- [ ] Model optimization for edge deployment
- [ ] Comprehensive documentation and reporting

## Contributing

Contributions to this project are welcome! Please feel free to submit issues or pull requests.

## Credits

This project was developed for the Space Station Object Detection Hackathon using:
- [YOLOv8](https://github.com/ultralytics/ultralytics) by Ultralytics
- Synthetic data generated by Duality AI's Falcon simulator

